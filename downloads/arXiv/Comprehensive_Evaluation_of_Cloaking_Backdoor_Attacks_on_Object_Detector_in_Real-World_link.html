<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Comprehensive Evaluation of Cloaking Backdoor Attacks on Object Detector
  in Real-World</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; background-color: #f5f5f5; }
        .container { background-color: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
        .paper-info { background: #f8f9fa; padding: 20px; border-radius: 5px; margin-bottom: 20px; }
        .link { margin: 20px 0; text-align: center; }
        a { 
            color: #0066cc; 
            text-decoration: none; 
            background-color: #e3f2fd;
            padding: 10px 20px;
            border-radius: 5px;
            display: inline-block;
            transition: all 0.3s;
        }
        a:hover { 
            background-color: #bbdefb;
            transform: translateY(-2px);
        }
        h1 { color: #333; border-bottom: 2px solid #0066cc; padding-bottom: 10px; }
        .meta { color: #666; margin: 5px 0; }
        .abstract { background-color: #fafafa; padding: 15px; border-left: 4px solid #0066cc; margin: 15px 0; }
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ“„ Comprehensive Evaluation of Cloaking Backdoor Attacks on Object Detector
  in Real-World</h1>
        
        <div class="paper-info">
            <div class="meta"><strong>ğŸ‘¥ ä½œè€…:</strong> Hua Ma, Alsharif Abuadbba, Yansong Gao, Hyoungshick Kim, Surya Nepal</div>
            <div class="meta"><strong>ğŸ“… å‘å¸ƒæ—¥æœŸ:</strong> 2025-01-25</div>
            <div class="meta"><strong>ğŸ“š æ¥æº:</strong> arXiv</div>
            
            
        </div>
        
        <div class="abstract">
            <strong>ğŸ“ æ‘˜è¦:</strong><br>
            The exploration of backdoor vulnerabilities in object detectors, particularly
in real-world scenarios, remains limited. A significant challenge lies in the
absence of a natural physical backdoor dataset, and constructing such a dataset
is both time- and labor-intensive. In this work, we address this gap by
creating a large-scale dataset comprising approximately 11,800 images/frames
with annotations featuring natural objects (e.g., T-shirts and hats) as
triggers to incur cloaking adversarial effects in diverse real-world scenarios.
This dataset is tailored for the study of physical backdoors in object
detectors. Leveraging this dataset, we conduct a comprehensive evaluation of an
insidious cloaking backdoor effect against object detectors, wherein the
bounding box around a person vanishes w...
        </div>
        
        <div class="link">
            <h3>ğŸ”— è®¿é—®åŸæ–‡:</h3>
            <a href="http://arxiv.org/abs/2501.15101v1" target="_blank">
                ç‚¹å‡»è®¿é—®åŸæ–‡ â†’
            </a>
        </div>
        
        <div style="text-align: center; color: #888; font-size: 12px; margin-top: 30px;">
            <p>ğŸ“„ ç”±æœºå™¨è§†è§‰æ–‡çŒ®è·å–ç³»ç»Ÿç”Ÿæˆ</p>
            <p>ğŸ•’ ç”Ÿæˆæ—¶é—´: 2025-05-26 23:56:03</p>
        </div>
    </div>
</body>
</html>