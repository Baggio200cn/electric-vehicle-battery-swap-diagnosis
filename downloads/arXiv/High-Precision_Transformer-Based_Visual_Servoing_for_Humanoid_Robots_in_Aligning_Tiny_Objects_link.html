<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>High-Precision Transformer-Based Visual Servoing for Humanoid Robots in
  Aligning Tiny Objects</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; background-color: #f5f5f5; }
        .container { background-color: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
        .paper-info { background: #f8f9fa; padding: 20px; border-radius: 5px; margin-bottom: 20px; }
        .link { margin: 20px 0; text-align: center; }
        a { 
            color: #0066cc; 
            text-decoration: none; 
            background-color: #e3f2fd;
            padding: 10px 20px;
            border-radius: 5px;
            display: inline-block;
            transition: all 0.3s;
        }
        a:hover { 
            background-color: #bbdefb;
            transform: translateY(-2px);
        }
        h1 { color: #333; border-bottom: 2px solid #0066cc; padding-bottom: 10px; }
        .meta { color: #666; margin: 5px 0; }
        .abstract { background-color: #fafafa; padding: 15px; border-left: 4px solid #0066cc; margin: 15px 0; }
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ“„ High-Precision Transformer-Based Visual Servoing for Humanoid Robots in
  Aligning Tiny Objects</h1>
        
        <div class="paper-info">
            <div class="meta"><strong>ğŸ‘¥ ä½œè€…:</strong> Jialong Xue, Wei Gao, Yu Wang, Chao Ji, Dongdong Zhao, Shi Yan, Shiwu Zhang</div>
            <div class="meta"><strong>ğŸ“… å‘å¸ƒæ—¥æœŸ:</strong> 2025-03-06</div>
            <div class="meta"><strong>ğŸ“š æ¥æº:</strong> arXiv</div>
            
            
        </div>
        
        <div class="abstract">
            <strong>ğŸ“ æ‘˜è¦:</strong><br>
            High-precision tiny object alignment remains a common and critical challenge
for humanoid robots in real-world. To address this problem, this paper proposes
a vision-based framework for precisely estimating and controlling the relative
position between a handheld tool and a target object for humanoid robots, e.g.,
a screwdriver tip and a screw head slot. By fusing images from the head and
torso cameras on a robot with its head joint angles, the proposed
Transformer-based visual servoing method can correct the handheld tool's
positional errors effectively, especially at a close distance. Experiments on
M4-M8 screws demonstrate an average convergence error of 0.8-1.3 mm and a
success rate of 93\%-100\%. Through comparative analysis, the results validate
that this capability of high-precision...
        </div>
        
        <div class="link">
            <h3>ğŸ”— è®¿é—®åŸæ–‡:</h3>
            <a href="http://arxiv.org/abs/2503.04862v1" target="_blank">
                ç‚¹å‡»è®¿é—®åŸæ–‡ â†’
            </a>
        </div>
        
        <div style="text-align: center; color: #888; font-size: 12px; margin-top: 30px;">
            <p>ğŸ“„ ç”±æœºå™¨è§†è§‰æ–‡çŒ®è·å–ç³»ç»Ÿç”Ÿæˆ</p>
            <p>ğŸ•’ ç”Ÿæˆæ—¶é—´: 2025-05-26 23:31:51</p>
        </div>
    </div>
</body>
</html>